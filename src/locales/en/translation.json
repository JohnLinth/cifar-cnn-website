{
    "I can tell if an image is of a...": "I can tell if an image is of a...",
    "Object Classifier": "Object Classifier",
    "title": "CCN - Image Classification",
    "✈️ Airplane 🚗 Automobile 🐦 Bird 🐱 Cat 🦌 Deer 🐶 Dog 🐸 Frog 🐴 Horse 🚢 Ship 🚚 Truck": "✈️ Airplane 🚗 Automobile 🐦 Bird 🐱 Cat 🦌 Deer 🐶 Dog 🐸 Frog 🐴 Horse 🚢 Ship 🚚 Truck",
    "Click or Drop Image": "Click or Drop Image Here",
    "Predict!": "Predict!",
    "This image was predicted to be a...": "This image was predicted to be a...",
    "No prediction yet": "No prediction yet",
    "Waiting for prediction...": "Waiting for prediction...",
    "Must select image first!": "Must select image first!",
    "HORSE": "HORSE",
    "AIRPLANE": "AIRPLANE",
    "AUTOMOBILE": "AUTOMOBILE",
    "BIRD": "BIRD",
    "CAT": "CAT",
    "DEER": "DEER",
    "DOG": "DOG",
    "FROG": "FROG",
    "SHIP": "SHIP",
    "TRUCK": "TRUCK",
    "app_description": "This app uses a Convolutional Neural Network (CNN) I trained to classify images into one of 10 classes. The model was trained on the CIFAR-10 dataset",
    "dataset_description": ", which consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class. These classes include categories like airplanes, automobiles, birds, cats etc.",
    "model_accuracy": "The model can predict the object in the image with ~72% accuracy, this varies with the clarity of the image (factors such as whether the object is fully in frame, its orientation, or if it’s clear and properly lit, can all affect the outcome)",
    "code_and_dataset_link": "The code I used to train and use the model is linked below as well as the data set I used to train it. Feel free to check it out!",
    "how_it_works": "How it works",
    "step_1": "1. Preprocessing",
    "step_1_description": "First the uploaded image is converted into a 32x32 image with 3 RGB channels to match the dataset it was trained on.",
    "example": "Example:",
    "step_2": "2. Feature Extraction",
    "step_2_description": "The core of this model is built using something called '2D convolutional layers', which are responsible for detecting features like edges, textures, and other structural patterns in the image. The deeper layers of this network detect more complex features, like shapes or specific parts of an object.",
    "step_3": "3. Max Pooling Layers",
    "step_3_description": "Between the convolutional layers, the model uses max pooling layers. These layers reduce the 'spatial dimensions', where only the most important features are retained while less useful information is discarded. This helps make the model more efficient and better at generalizing.",
    "step_4": "4. Classification / Prediction",
    "step_4_description": "After the feature extraction process, the data passes through fully connected 'Dense layers'. These layers combine all extracted features and make a final prediction. The model assigns probabilities to each of the 10 possible classes, and the class with the highest probability is selected as the predicted object.",
    "The Prediction Process (Step-by-Step)": "The Prediction Process (Step-by-Step)",
    "be patient, sometimes the prediction can take a few seconds..." : "be patient, sometimes the prediction can take a few seconds...",
    "Check out the code": "Check out the code",
    "sources": "Useful Material",
    "designed and developed by john linthicum © sep. 2024": "Designed and Developed by John Linthicum © Sep. 2024"
}